name: Ejecutar Scraper cada 2 horas

on:
  # schedule:
    # - cron: '0 0 * * *'   # 00:00 UTC
    # - cron: '0 2 * * *'   # 02:00 UTC
    # - cron: '0 4 * * *'   # 04:00 UTC
    # - cron: '0 6 * * *'   # 06:00 UTC
    # - cron: '0 8 * * *'   # 08:00 UTC
    # - cron: '0 10 * * *'  # 10:00 UTC
    # - cron: '0 12 * * *'  # 10:00 UTC
    # - cron: '0 14 * * *'  # 10:00 UTC
    # - cron: '0 16 * * *'  # 10:00 UTC
    # - cron: '0 18 * * *'  # 10:00 UTC
    # - cron: '0 20 * * *'  # 10:00 UTC
    # - cron: '0 22 * * *'  # 10:00 UTC
  workflow_dispatch:      # Permite ejecuci√≥n manual

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Clonar el repositorio
      uses: actions/checkout@v3

    - name: Configurar Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Ejecutar scraper
      env:
        DB_HOST: ${{ secrets.DB_HOST }}
        DB_NAME: ${{ secrets.DB_NAME }}
        DB_USER: ${{ secrets.DB_USER }}
        DB_PASS: ${{ secrets.DB_PASS }}
        DB_PORT: ${{ secrets.DB_PORT }}
        SERPER_API_KEY: ${{ secrets.SERPER_API_KEY }}
      run: python main.py
